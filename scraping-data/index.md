# Data Acquisition

Data acquisition is the process of collecting or sampling data from a source. In the context of Computer Science, this often means downloading a database from a source on the internet. However, sometimes a website might not give an option to download the data, but does present it (think of websites like Wikipedia or Twitter).

Web scraping is a way of extracting data from websites. While this process could be done manually (by reading information on a website, and then copying that information to a file) it is usually done through the use of software. Scraping can be a valuable tool for extracting data.

In this module, we will focus on scraping data from the Internet Movie Database (IMDb). This website is an online database of information related to films, programs, home videos, games, and streaming content. It includes information like cast, production crew and personal biographies, plot summaries, trivia, ratings, and fan and critic reviews.

In the second part of the module, we will focus on a second technique: web crawling. Web crawling is a technique where a program visits multiple webpages and scrapes the page for information. An example fo where this technique is used, is by search engines to update their web content. In our case, we will use it to scrape information from different pages.y.
